{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC<sup>2</sup> : Multiparty Collaboration & Coopetition\n",
    "MC<sup>2</sup> contains a series of subprojects in the RISE Lab, all pertaining to multiparty collaboration and coopetition. The particular project we'll be giving a tutorial on today is Federated XGBoost, an extension of the existing gradient boosting machine learning framework that enables use of the framework in the federated setting. This is particularly important for use cases that focus on low bandwidth training across multiple parties.\n",
    "\n",
    "You can find the codebase here: https://github.com/mc2-project/mc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Introduction\n",
    "### Allstate Claim Prediction Dataset\n",
    "This dataset is used in the original XGBoost paper and is taken from a Kaggle competition.\n",
    "The goal of the competition is to predict insurance claim payments given multiple datapoints about the insured vehicle. Further information can be found [here](https://www.kaggle.com/c/ClaimPredictionChallenge).\n",
    "\n",
    "We propose a use case where some insurance company has multiple departments specializing in different makes of cars, and these departments are unable to share data between them.\n",
    "As such, a sample of the original Allstate Claim Prediction dataset is partitioned here into four groups, each of which represents one of these departments.\n",
    "In the following exercises, you will represent one such department, and your task will be to use the information provided to predict whether new insurance claims will be greater than 0, or equal to 0. (binary classification).\n",
    "You will then collaborate with the other departments, using our approach to jointly train a model without revealing all of your department's data to other parties.\n",
    "\n",
    "We will be calling this the `insurance` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a federation, please get into groups of 3 or 4. Choose one member of the team to act as the aggregator. The aggregator will have a `party_id` of 1. Assign all other members of the federation a `party_ID` from 2 to 4. Keep your `party_id` handy for the rest of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "Now that we've finished with setup, it's time to start the exercises. Depending on your role (as either the aggregator or a non-aggregator), you will be working in different notebooks. This tutorial consists of a setup phase and three exercises:\n",
    "\n",
    "  1. Setup [[Aggregator](./setup-aggregator.ipynb), [Member](./setup-member.ipynb)]\n",
    "  2. Single Party XGBoost on Data Subset [[Aggregator](./exercise1-aggregator.ipynb), [Member](./exercise1-member.ipynb)]\n",
    "  3. Multiparty XGBoost with Centralized Training [[Aggregator](./exercise2-aggregator.ipynb), [Member](./exercise2-member.ipynb)]\n",
    "  4. Multiparty XGBoost with Federated Training [[Aggregator](./exercise3-aggregator.ipynb), [Member](./exercise3-member.ipynb)]\n",
    "\n",
    "Let's start with Setup [[Aggregator](./setup-aggregator.ipynb), [Member](./setup-member.ipynb)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
