{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 6 - Training with Ray and Serving with Clipper\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to train a policy with Ray and to deploy it with Clipper in a fun, interactive way.\n",
    "\n",
    "We will train an agent to play Pong, and then we will play Pong against the policy that we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import pong_py\n",
    "import ray\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents import ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an agent that can be trained using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    return pong_py.PongJSEnv()\n",
    "\n",
    "register_env(\"my_env\", env_creator)\n",
    "# ray.init()\n",
    "trainer = ppo.PPOAgent(env=\"my_env\", config={\n",
    "    \"env_config\": {},  # config to pass to env creator\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the `PPOAgent` for some number of iterations.\n",
    "\n",
    "**EXERCISE:** You will need to experiment with the number of iterations as well as with the configuration to get the agent to learn something reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the agent manually by calling `agent.compute_action` and see the rewards you get are consistent with the rewards printed during the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pong_py.PongJSEnv()\n",
    "\n",
    "for _ in range(20):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    cumulative_reward = 0\n",
    "    print(state)\n",
    "\n",
    "    while not done:\n",
    "        action = trainer.compute_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        cumulative_reward += reward\n",
    "\n",
    "    print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the agent so that the relevant model can be saved and deployed to Clipper. We save the name of the checkpoint file in `metadata.json` so the model container knows how to restore the policy checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# checkpoint_path = trainer.save()\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# checkpoint_file = os.path.basename(checkpoint_path)\n",
    "# with open(os.path.join(checkpoint_dir, \"metadata.json\"), \"w\") as f:\n",
    "#     json.dump({\"checkpoint\": checkpoint_file}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Against the Policy\n",
    "\n",
    "In this section, we will play Pong against the policy that we just trained. The game will be played in your browser, and the policy that we trained will be served by Clipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_doubles(trainer, states):\n",
    "    start = datetime.now()\n",
    "    actions = [str(trainer.compute_action(s)) for s in states]\n",
    "    end = datetime.now()\n",
    "    print(\"Computed action in {} ms\".format((end-start).total_seconds() * 1000.0))\n",
    "    return actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Deploy your policy using Clipper. Follow the instructions that get printed below to play Pong against the deployed policy. You'll need to deploy all of the data that is saved in the directory `os.path.dirname(checkpoint_path)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the `clipper_admin` library and use that to create a new Clipper instance to serve the policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create your ClipperConnection, you need to tell it how to communicate with the Docker service and Clipper. You can use the following command to get the Docker IP address. Use that address when you create your `ClipperConnection` in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make logging work correctly in the Jupyter notebook\n",
    "import logging\n",
    "import sys\n",
    "import subprocess\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from clipper_admin import DockerContainerManager, ClipperConnection\n",
    "from clipper_admin.deployers import python as py_deployer\n",
    "docker_ip = subprocess.check_output(\"./get_docker_ip.sh\").strip()\n",
    "print(docker_ip)\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "# Add a call to stop all in case you still have Clipper running from the earlier exercises\n",
    "clipper_conn.stop_all()\n",
    "# clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, deploy the saved policy checkpoint to Clipper using a Docker image we created for this exercise (similar to the TensorFlow model container in the Clipper tutorial). If you're curious, you can find the custom model container code on [GitHub](https://github.com/ucbrise/risecamp/blob/077aa51078e2043d4d3d2d539e256c30c259678e/rl_and_pong/pong_model_container.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from clipper_admin.deployers import rllib as rllib_deployer\n",
    "from auth_deployer import auth_deploy_rllib_model\n",
    "model_name = \"pong-policy\"\n",
    "app_name = \"pong\"\n",
    "\n",
    "\n",
    "#Example call to auth_deploy_model\n",
    "# TODO: need to provide the following parameters:\n",
    "# 1. wave_obj\n",
    "# 2. recipient_entity\n",
    "# 3. ciphertext\n",
    "auth_deploy_rllib_model(\n",
    "    clipper_conn,\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    input_type=\"doubles\",\n",
    "    func=predict_doubles,\n",
    "    wave_obj,\n",
    "    recipient_entity,\n",
    "    ciphertext\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE FOR LOGISTIC REGRESSION MODEL\n",
    "from auth_deployer import auth_deploy_python_model\n",
    "\n",
    "model_name = \"pong-policy\"\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(training_data, labels)\n",
    "\n",
    "def predict(inputs):\n",
    "    # model.predict returns a list of predictions\n",
    "    preds = model.predict(inputs)\n",
    "    return [str(p) for p in preds]\n",
    "\n",
    "#only difference is the func provided and python vs rllib model\n",
    "auth_deploy_python_model(\n",
    "    clipper_conn,\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    input_type=\"doubles\",\n",
    "    func=predict,\n",
    "    wave_obj,\n",
    "    recipient_entity,\n",
    "    ciphertext\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, register a Clipper application and link it the deployed policy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pong-policy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_linked_models(app_name=\"pong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[default-cluster] Application pong was successfully registered\n",
      "[default-cluster] Model pong-policy is now linked to application pong\n"
     ]
    }
   ],
   "source": [
    "app_name = \"pong\"\n",
    "clipper_conn.register_application(name=app_name, default_output=\"0\", input_type=\"doubles\", slo_micros=100000)\n",
    "clipper_conn.link_model_to_app(app_name=app_name, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have deployed your policy to Clipper, you will start a Pong application that will let you play against your policy in the browser.\n",
    "\n",
    "When you start the application, you need to tell it where Clipper is running in order for the Pong application to request predictions from Clipper. `ClipperConnection` provides the `get_query_addr()` method to get the IP address and port on which Clipper is listening for incoming prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipper address: localhost:1337\n"
     ]
    }
   ],
   "source": [
    "clipper_addr = clipper_conn.get_query_addr()\n",
    "print(\"Clipper address: {}\".format(clipper_addr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start the Pong webserver. It will print out the URL it's running on after it starts. Copy and paste that URL into your browser and press \"1\" to play against your policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python javascript-pong/pong-server.py localhost:1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (52) Empty reply from server\r\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST --header \"Content-Type:application/json\" -d '{\"input\": [1.1, 2.2, 3.3]}' 127.0.0.1:1337/pong/predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess32 as subprocess\n",
    "server_handle = subprocess.Popen([\"./start_webserver.sh\", clipper_addr], stdout=subprocess.PIPE)\n",
    "print(server_handle.stdout.readline().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a New Policy\n",
    "\n",
    "The first policy that you deploy probably won't be a very strong competitor, especially if you only trained it for a few iterations. Try training it for more iterations and deploying the new policy to Clipper. Clipper will automatically switch the Pong application to query the new version of the policy. You don't need to reload the page or even restart the game.\n",
    "\n",
    "For your convenience, we've copied the relevant cells from above to train the policy for more iterations and deploy it Clipper. You can run this cell as many times as you want. Don't forget to increment the version number of the model each time you deploy to Clipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train for more iterations\n",
    "for i in range(50):\n",
    "    result = agent.train()\n",
    "    \n",
    "# Save the new policy\n",
    "checkpoint_path = agent.save()\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint_file = os.path.basename(checkpoint_path)\n",
    "with open(os.path.join(checkpoint_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump({\"checkpoint\": checkpoint_file}, f)\n",
    "    \n",
    "# Deploy the new policy to Clipper.\n",
    "clipper_conn.build_and_deploy_model(\n",
    "    name=model_name,\n",
    "    version=2, # If you run this more than once, don't forget to keep updating the version.\n",
    "    input_type=\"doubles\",\n",
    "    model_data_path=os.path.dirname(checkpoint_path),\n",
    "    base_image=\"clipper/risecamp-pong-container\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
