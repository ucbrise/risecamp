{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Matrix Computations\n",
    "\n",
    "In this notebookwe will walk through some of the more advanced things you can achieve with PyWren. Namely using S3 as a backing store we will implement a nearest neighbor classifier algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import boto3\n",
    "import cloudpickle\n",
    "import itertools\n",
    "import concurrent.futures as fs\n",
    "import io\n",
    "import numpy as np\n",
    "import time\n",
    "from importlib import reload\n",
    "from sklearn import metrics\n",
    "import pywren\n",
    "import pywren.wrenconfig as wc\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_BUCKET = wc.default()['s3']['bucket']\n",
    "# monkey patch runtime\n",
    "config = wc.default()\n",
    "config['runtime']['s3_bucket'] = 'ericmjonas-public'\n",
    "config['runtime']['s3_key'] = 'pywren.runtime/pywren_runtime-3.6-default.tar.gz'\n",
    "pwex = pywren.default_executor(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about PyWren is it allows users to integrate existing python libraries easily.\n",
    "For the following exercise, we are going to use some popular python libraries, e.g., NumPy, to work on some matrix multiplication problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_function(b):\n",
    "    x = np.random.normal(0, b, 1024)\n",
    "    A = np.random.normal(0, b, (1024, 1024))\n",
    "    return np.dot(A, x)\n",
    "\n",
    "pwex = pywren.default_executor()\n",
    "res = pwex.map(my_function, np.linspace(0.1, 10, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distributed Nearest Neighbor with Large Scale Matrix Multiplication \n",
    "\n",
    "A problem with the above method is that, we are limited to working with \"small\" matrices, that fit in the memory of a single lambda instance. With a little work we can write a \"ShardedMatrix\" wrapper that shards numpy matrices across S3 objects (the source code for this can be found in matrix.py) This allows us to use PyWren's map functionality to access different parts of the matrix. We can further use this functionality to compute a large scale matrix multiplication.\n",
    "\n",
    "\n",
    "In the below example we will implement a distributed nearest neighbor implementation on top of PyWren and this ShardedMatrix abstraction. Note that nearest neighbor is often a hard to implement algorithm on BSP systems such as Apache Spark due to a high communication cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets download the mnist dataset. This cell should take about 3 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fetch_mldata('MNIST original', data_home=\"/tmp/\")['data'].astype('float32')\n",
    "y = fetch_mldata('MNIST original', data_home=\"/tmp/\")['target']\n",
    "X_train = X[:60000, :]\n",
    "y_train = y[:60000, np.newaxis]\n",
    "\n",
    "X_test = X[60000:, :]\n",
    "y_test = y[60000:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now \"shard\" the mnist matrix with a shard_size of 4000, what this means is that, we will convert the 60000 by 784 matrix into 30 separate 4000 x 784 numpy matrices that will be split across different S3 Keys. The first argument is the S3 folder where these submatrices can be found. This cell should take about 3 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time X_train_sharded = matrix.ShardedMatrix(\"x_train\", shape=X_train.shape, bucket=DEFAULT_BUCKET, shard_sizes=[4000,784])\n",
    "%time X_train_sharded.shard_matrix(X_train, n_jobs=16)\n",
    "\n",
    "%time X_test_sharded = matrix.ShardedMatrix(\"x_test\", shape=X_test.shape, bucket=DEFAULT_BUCKET, shard_sizes=[4000,784])\n",
    "%time X_test_sharded.shard_matrix(X_test, n_jobs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our sharded matrices we can compute a local nearest neighbor classifier and compare it with one we will compute with PyWren. If we do everything correctly the PyWren implementation should be identical to the local one, but with a better scaling with dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_local_nearest_neighbor_labels(X_train, X_test, y_test, y_train):\n",
    "    # compute a distance matrix\n",
    "    train_norms = np.linalg.norm(X_train, axis=1)[:, np.newaxis] ** 2\n",
    "    test_norms = np.linalg.norm(X_test, axis=1)[np.newaxis, :] ** 2\n",
    "    return y_train[np.argmin(train_norms + -2*X_train.dot(X_test.T)+ test_norms, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time y_test_pred = compute_local_nearest_neighbor_labels(X_train, X_test, y_test, y_train)\n",
    "print(\"Accuracy is \", metrics.accuracy_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try using PyWren.\n",
    "Our strategy will be to use PyWren to map over (training point, testing point) pairs (in a blockwise fashion), and generate the distance matrix in a sharded form. Then we can launch another PyWren job to extract the nearest neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an \"empty\" ShardedMatrix on S3 (we will fill this Matrix in with pywren)\n",
    "D_sharded = matrix.ShardedMatrix(\"D\", shape=(X_train.shape[0], X_test.shape[0]), shard_sizes=[4000,4000], bucket=DEFAULT_BUCKET)\n",
    "\n",
    "def compute_pywren_nearest_neighbor_distance_matrix(block_pair, X_train_sharded, X_test_sharded, D_sharded):\n",
    "    block0,block1 = block_pair\n",
    "    # compute a distance matrix block\n",
    "    X_train_block = X_train_sharded.get_block(block0, 0)\n",
    "    X_test_block = X_test_sharded.get_block(block1, 0)\n",
    "    # fill me in \n",
    "    D_block = # local distance matrix between X_train_block and X_test_block\n",
    "    D_sharded.put_block(block0, block1, D_block)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pywren to map across the indices of the \"empty\" sharded matrix D_sharded by mapping over D_sharded.block_idxs. Each element of block_idxs corresponds to the (block) index of a 4000 x 4000 submatrix of D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_sharded.block_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What function would we write so that we can map over these \"empty\" indices such that it fills in the entire matrix\n",
    "pywren_distance_function = # fill me in  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that our function works locally\n",
    "pywren_distance_function((0,0)) # compute the first block of distance matrix\n",
    "D_sharded.get_block((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D_sharded.block_idxs corresponds to block indices of the sharded distance matrix \n",
    "\n",
    "# fill in the distance matrix in parallel\n",
    "%time futures = pwex.map(pywren_distance_function, D_sharded.block_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time pywren.wait(futures)\n",
    "[f.result() for f in futures] # make sure nothing exceptioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the distance matrix we can use pywren to find the local (rowwise) argmin of each sub-block of our matrix and then take a global min locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_argmin(block_pair, D_sharded):\n",
    "    '''given a sub block of D matrix return  (cols, block-rowwise-argmin, block-rowwise-min)\n",
    "       Note: rowwise means across rows\n",
    "    '''\n",
    "    D_block = D_sharded.get_block(*block_pair)\n",
    "    offset = block_pair[0]*D_sharded.shard_sizes[0] \n",
    "    return (block_pair[1], offset + np.argmin(D_block, axis=0), np.min(D_block, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now if we want to find the local argmin of every block what function would we map over? \n",
    "%time futures = pwex.map(       ,        ) # Fill me in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time pywren.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_results_from_pywren(results):\n",
    "    ''' take the pywren find_argmin result tuples of (test_block_idx, block-rowwise_argmin, block-rowwise_min)\n",
    "        and return a list of rowwise-argmin. We are essentially writing a local reduce function here'''\n",
    "    mins = []\n",
    "    for _, group in itertools.groupby(sorted(results, key=itemgetter(0)), key=itemgetter(0)):\n",
    "        # fill me in \n",
    "        pass\n",
    "    return np.hstack(mins)\n",
    "\n",
    "\n",
    "y_test_pred_pywren = y_train[compute_results_from_pywren(results)]\n",
    "print(\"Accuracy is \", metrics.accuracy_score(y_test, y_test_pred_pywren))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of this PyWren implementation is that we are executing in parallel over the entire matrix. So as we get more training and test points our implementation will scale gracefully along with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Training 1-NN\n",
    "\n",
    "So one advantage of this PyWren implementation is that we can compute the training accuracy of our NN classifier.\n",
    "Normally this is hard because the training distance matrix is 60000 x 60000. Which is around 10 GB and can be quite cumbersome to compute (and may not even fit in your local ram!).\n",
    "\n",
    "(We know apriori for 1-NN it is always going to be 100% but we can verify that quickly with PyWren)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an \"empty\" ShardedMatrix on S3 (we will fill this Matrix in with pywren)\n",
    "D_train_sharded = matrix.ShardedMatrix(\"D\", shape=#FILL ME IN, shard_sizes=[4000,4000], bucket=DEFAULT_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pywren_train_distance_function = #fill me in \n",
    "%time futures = pwex.map( , D_train_sharded.block_idxs) # fill me in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time pywren.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time futures = # fill me in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time pywren.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training Accuracy is \", metrics.accuracy_score(y_train, y_train[compute_results_from_pywren(results)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
