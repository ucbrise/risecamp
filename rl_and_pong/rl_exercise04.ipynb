{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Exercise 6 - Training with Ray and Serving with Clipper\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to train a policy with Ray and to deploy it with Clipper in a fun, interactive way.\n",
    "\n",
    "We will train an agent to play Pong, and then we will play Pong against the policy that we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import pong_py\n",
    "import ray\n",
    "\n",
    "from ray.rllib.ppo import PPOAgent, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ray.init(num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is a hack. The explanation is as follows. Internally within the `PPOAgent` constructor, a number of actors are created, and these actors will instantiate gym environments using the command `gym.make('PongJS-v0')`. The command `gym.make` knows how to instantiate a number of pre-defined environments that are shipped with the `gym` module. However, the `PongJS-v0` environment is defined in the `pong_py` module and is registered with the `gym` module when the `import pong_py` statement gets run.\n",
    "\n",
    "Therefore, for the actors to successfully instantiate the gym environments, the `pong_py` module must be imported on the actors. This is why we define a remote function `import_pong_py` which closes over the `pong_py` environment. When the actors are created, that remote function is unpickled on the actors which forces the `pong_py` module to be imported, which enables the `gym` module to create the `PongJS-v0` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a hack.\n",
    "@ray.remote\n",
    "def import_pong_py():\n",
    "    pong_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an agent that can be trained using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "# Consider using more workers to speed up the rollouts.\n",
    "config['num_workers'] = 3\n",
    "config['gamma'] = 0.99\n",
    "config['sgd_stepsize'] = 5e-3\n",
    "config['kl_coeff'] = 0.1\n",
    "config['num_sgd_iter'] = 20\n",
    "config['sgd_batchsize'] = 8196\n",
    "config['observation_filter'] = 'NoFilter'\n",
    "config['model']['fcnet_hiddens'] = [32, 32]\n",
    "\n",
    "agent = PPOAgent('PongJS-v0', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the `PPOAgent` for some number of iterations.\n",
    "\n",
    "**EXERCISE:** You will need to experiment with the number of iterations as well as with the configuration to get the agent to learn something reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the agent manually by calling `agent.compute_action` and see the rewards you get are consistent with the rewards printed during the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('PongJS-v0')\n",
    "\n",
    "for _ in range(20):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    cumulative_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        cumulative_reward += reward\n",
    "\n",
    "    print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the agent so that the relevant model can be saved and deployed to Clipper. We save the name of the checkpoint file in `metadata.json` so the model container knows how to restore the policy checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "checkpoint_path = agent.save()\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint_file = os.path.basename(checkpoint_path)\n",
    "with open(os.path.join(checkpoint_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump({\"checkpoint\": checkpoint_file}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Against the Policy\n",
    "\n",
    "In this section, we will play Pong against the policy that we just trained. The game will be played in your browser, and the policy that we trained will be served by Clipper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Deploy your policy using Clipper. Follow the instructions that get printed below to play Pong against the deployed policy. You'll need to deploy all of the data that is saved in the directory `os.path.dirname(checkpoint_path)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the `clipper_admin` library and use that to create a new Clipper instance to serve the policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create your ClipperConnection, you need to tell it how to communicate with the Docker service and Clipper. You can use the following command to get the Docker IP address. Use that address when you create your `ClipperConnection` in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make logging work correctly in the Jupyter notebook\n",
    "import logging\n",
    "import sys\n",
    "import subprocess32 as subprocess\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from clipper_admin import DockerContainerManager, ClipperConnection\n",
    "docker_ip = subprocess.check_output(\"./get_docker_ip.sh\").strip()\n",
    "clipper_conn = ClipperConnection(DockerContainerManager(docker_ip_address=docker_ip))\n",
    "# Add a call to stop all in case you still have Clipper running from the earlier exercises\n",
    "clipper_conn.stop_all()\n",
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, deploy the saved policy checkpoint to Clipper using a Docker image we created for this exercise (similar to the TensorFlow model container in the Clipper tutorial). If you're curious, you can find the custom model container code on [GitHub](https://github.com/ucbrise/risecamp/blob/master/pong/pong_model_container.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_name = \"pong-policy\"\n",
    "app_name = \"pong\"\n",
    "clipper_conn.build_and_deploy_model(\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    input_type=\"doubles\",\n",
    "    model_data_path=os.path.dirname(checkpoint_path),\n",
    "    base_image=\"clipper/risecamp-pong-container\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, register a Clipper application and link it the deployed policy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_name = \"pong\"\n",
    "clipper_conn.register_application(name=app_name, default_output=\"0\", input_type=\"doubles\", slo_micros=100000)\n",
    "clipper_conn.link_model_to_app(app_name=app_name, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have deployed your policy to Clipper, you will start a Pong application that will let you play against your policy in the browser.\n",
    "\n",
    "When you start the application, you need to tell it where Clipper is running in order for the Pong application to request predictions from Clipper. `ClipperConnection` provides the `get_query_addr()` method to get the IP address and port on which Clipper is listening for incoming prediction requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_addr = clipper_conn.get_query_addr()\n",
    "print(\"Clipper address: {}\".format(clipper_addr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess32 as subprocess\n",
    "server_handle = subprocess.Popen([\"./start_webserver.sh\", clipper_addr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to port 3000 on the same host as the one running this notebook. If you're running locally, that's <http://localhost:3000>. If you're running on EC2, that's `<EC2_HOSTNAME:3000>`.\n",
    "**TODO:** Figure out what address they should actually go to.\n",
    "\n",
    "**TODO:** Instructions on how to deploy a new version of the policy to Clipper."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2 for Clipper",
   "language": "python",
   "name": "clipper_py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
